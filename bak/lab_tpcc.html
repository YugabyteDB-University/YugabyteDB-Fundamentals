<div class="fr-view">

	<p>⏰ &nbsp;Lab time is 20 min&nbsp;</p>
	<hr>

	<h2 id="about-this-lab">About this lab</h2>

	<p>In this lab, you will download, install, and run the Yugabyte TPCC benchmark. The benchmark is for Online Transaction Processing (OLTP) workloads. As such, it uses the <a href="" rel="noopener noreferrer" target="_blank">YSQL API</a>. This lab consists of the following activities:</p>

	<ul>
		<li>Download and install the Yugabyte TPCC benchmark</li>
		<li>Load the data for the benchmark</li>
		<li>Run the benchmark</li>
		<li>Review the benchmark results</li>
		<li>Experiment on your own</li>
	</ul>

	<h3 id="about-the-tpc-c-benchmark">About the TPC-C benchmark</h3>

	<p>This TPC-C benchmark is from <a href="https://www.tpc.org/" rel="noopener noreferrer" target="_blank">TPC.org</a>. The YugabyteDB version of closely follows the TPC-C v5.11.0 specification. The aim of the <a href="http://tpc.org/tpcc/detail5.asp?" rel="noopener noreferrer" target="_blank">TPC-C</a> benchmark is to test how a database performs when handling transactions generated by a real-world OLTP application. To this end, the benchmark measures <strong>transactions per minute (tpmC)</strong>. The resulting TPM-C value is useful for comparing cluster topologies including geography, hardware, number of nodes, replication factor, and encryption in transit with TLS.</p>

	<p>The data model for the TPC-C benchmark is for a business that has at least one warehouse with an inventory of items, multiple districts to serve, and various orders that consists of several items. The benchmark represents five specific transaction types:</p>

	<ul>
		<li>The <strong>New Order</strong> transaction simulates entering a new order through a single database transaction. To satisfy online users, this transaction, which forms the backbone of the workload, has a high frequency of execution with low latency requirements. About 1% of these transactions simulate failures, requiring the rollback of the transaction.</li>
		<li>The <strong>Payment</strong> transaction updates the customer&rsquo;s balance and reflects the payment on the district and warehouse sales statistics. This transaction includes non-primary key access to the Customer table.</li>
		<li>The <strong>Order Status</strong> transaction queries the status of a customer&rsquo;s last order.</li>
		<li>The <strong>Delivery</strong> transaction processes a batch of new orders which are not yet delivered, executed in the background using a queuing mechanism.</li>
		<li>The <strong>Stock Level</strong> transaction determines the number of recently sold items that have a stock level below a specified threshold and therefore would need to be restocked.</li>
	</ul>

	<blockquote>

		<p><strong>Note</strong>: The <strong>number of warehouses</strong> is a key configurable parameter for scale of the benchmark. When you increase the number of warehouses, you increase the data set size, the number of concurrent clients, and the number of concurrently running transactions. The reason for the increase is that a warehouse represents up the number <strong>Point Of Sale (POS)</strong> or <strong>Point of Inquiry</strong> terminals. Terminals generate a variety of transactions such as a new order, a payment settlement, or an order status inquiry. A warehouse also represents behind the scenes database activities such as restock searches and delivery confirmations.</p>
	</blockquote>

	<p>While the benchmark portrays the activity of a wholesale supplier, TPC-C is not limited to the activity of any particular business segment, but, rather represents any business in an industry that must manage, sell, or distribute a product or service.</p>

	<h3 id="about-the-yugabyte-tpcc-benchmark">About the Yugabyte TPCC benchmark</h3>

	<p>The <a href="https://github.com/yugabyte/tpcc" rel="noopener noreferrer" target="_blank">Yugabyte TPCC benchmark</a> application is a fork of the popular <a href="https://github.com/oltpbenchmark/oltpbench" rel="noopener noreferrer" target="_blank">OLTPBench</a> benchmark tool.</p>

	<p>Just like the OLTPBench original, the Yugabyte TPCC benchmark is a multi-threaded load generator that is be able to produce a variety of workloads, including variations in rate and transaction type. The benchmark also allows for benchmark data collection. You can analyze this data to determine key metrics such as Transactions per Second (TPS) and Latency per Transaction Type. <strong>TPMC</strong> remains as the main metric for summarizing the benchmark.</p>

	<p>To run the TPCC benchmark, you use a utility script, <code>./tpccbenchmark</code>, which supports the following arguments:</p>
	<div class="highlight"><pre><code class="language-bash">-c,--config &lt;arg&gt;            [required] Workload configuration file
   --clear &lt;arg&gt;             Clear all records in the database for this
                             benchmark
   --create &lt;arg&gt;            Initialize the database for this benchmark
   --execute &lt;arg&gt;           Execute the benchmark workload
-h,--help                    Print this help
   --histograms              Print txn histograms
   --load &lt;arg&gt;              Load data using the benchmark&#39;s data loader
-o,--output &lt;arg&gt;            Output file (default System.out)
   --runscript &lt;arg&gt;         Run an SQL script
-s,--sample &lt;arg&gt;            Sampling window
-v,--verbose                 Display Messages
</code></pre></div>

	<p>The default benchmark values are:</p>

	<ul>
		<li>warehouses = 10</li>
		<li>total warehouses across shards = 10</li>
		<li>terminals = 100</li>
		<li>dbConnections = 10</li>
		<li>loaderThreads = 10</li>
	</ul>

	<p>A <a href="https://github.com/yugabyte/tpcc/blob/master/config/workload_all.xml" rel="noopener noreferrer" target="_blank"><code>config/workload_all.xml</code></a> file provides an example of how to describe and configure a workload.</p>

	<p>For more configurations, review the forked OLTP benchmark <a href="https://github.com/oltpbenchmark/oltpbench/blob/master/config/sample_tpcc_config.xml" rel="noopener noreferrer" target="_blank">config.xml</a>.</p>

	<p>The Yugabyte TPCC benchmark also supports multi-region cluster topologies row-level geo-partitioning. To see how, review the <a href="https://github.com/yugabyte/tpcc/blob/master/config/geopartitioned_workload.xml" rel="noopener noreferrer" target="_blank"><code>geopartitioned_workload.xml</code></a> file which illustrates how to specify tablespaces with specific placement policies.</p>

	<p>See the following:</p>

	<p>
		<a href="https://github.com/yugabyte/tpcc" target="_blank" rel="noopener noreferrer"></a></p>

	<ul>
		<li><a href="https://github.com/yugabyte/tpcc" rel="noopener noreferrer" target="_blank">https://github.com/yugabyte/tpcc</a>
			<br>
			<a href="https://docs.yugabyte.com/latest/benchmark/tpcc-ysql/" target="_blank" rel="noopener noreferrer"></a></li>
		<li><a href="https://docs.yugabyte.com/latest/benchmark/tpcc-ysql/" rel="noopener noreferrer" target="_blank">https://docs.yugabyte.com/latest/benchmark/tpcc-ysql/</a></li>
	</ul>

	<h3 id="requirements">Requirements</h3>

	<p>In order to complete this lab, you&#39;ll need the following:</p>

	<ul>
		<li>Your YugabyteDB Managed cluster</li>
	</ul>

	<h2 id="download-and-install-the-yugabyte-tpcc-benchmark">Download and install the Yugabyte TPCC benchmark</h2>

	<p>Follow these steps to download and install the benchmark:</p>

	<ul>
		<li>Install wget and Java, if needed.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">sudo yum install -y wget java</code></pre></div>

	<ul>
		<li>Download and uncompress the <code>tpcc.targ.gz</code> file.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">cd /tmp
wget https://github.com/yugabyte/tpcc/releases/download/2.1/tpcc.tar.gz
tar -zxvf tpcc.tar.gz
cd tpcc/</code></pre></div>

	<ul>
		<li>Create a copy of the <code>config/workload_all.xml</code> file.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">pwd
MY_TPCC_WORKLOAD_FILE=&#39;my_workload_all.xml&#39;
cp config/workload_all.xml config/${MY_TPCC_WORKLOAD_FILE}</code></pre></div>

	<ul>
		<li>Using VIM, edit your file.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">vim config/${MY_TPCC_WORKLOAD_FILE}</code></pre></div>

	<ul>
		<li>Edit the file and specify values for your username and password <code>[i = Insert mode ]</code>.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">&lt;username&gt;yugabyte&lt;/username&gt;
&lt;password&gt;my_password&lt;/password&gt;</code></pre></div>

	<ul>
		<li>

			<p>Save your changes <code>[ esc = Read-only mode | :wq! = force save quit ]</code> and exit.</p>
		</li>
		<li>

			<p>Verify you modifications.</p>
		</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">cat config/${MY_TPCC_WORKLOAD_FILE}</code></pre></div>

	<h2 id="load-the-data-for-the-benchmark">Load the data for the benchmark</h2>

	<p>Before starting your benchmark workload, you first need to create the TPCC data model and then load data. Here are the steps:</p>

	<ul>
		<li>First, specify the IPv4 address for your nodes, changing the IP values as needed to the Public IPv4 value of the node in your YugabyteDB Managed cluster.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">YB_NODE_1=&#39;us-east-1.728c85s99-6c16-406c-8059-567668989681.aws.ybdb.io&#39;
</code></pre></div>

	<ul>
		<li>Create the TPCC data model using the <code>--config</code>, <code>--create</code>, and <code>--nodes</code> arguments.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">
./tpccbenchmark --config=${MY_TPCC_WORKLOAD_FILE} --create=true  --nodes=${YB_NODE_1}</code></pre></div>

	<ul>
		<li>Load the data for the TPCC database using the <code>--config</code>, <code>--load</code>, <code>--nodes</code>, <code>--warehouses</code>, and <code>--loaderthreads</code> arguments.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash"> ./tpccbenchmark --config=${MY_TPCC_WORKLOAD_FILE} \
   --load=true  \
   --nodes=${YB_NODE_1}  \
   --warehouses=1 \
   --loaderthreads=2</code></pre></div>

	<p>Note: Depending on the vCPU of the nodes in your cluster and scale factor, the load time may be more than 10 minutes. The value of <code>--loaderthreads</code> typically represents the total number vCPU in your cluster. For example, <code>--loaderthreads</code> is 12 for a 3 node cluster with 4 vCPU per node.</p>

	<h2 id="run-the-benchmark">Run the benchmark</h2>

	<p>After you&#39;ve loaded the data for your benchmark, you can now run the benchmark. Here are the steps:</p>

	<ul>
		<li>Using the <code>--config</code>, <code>--execute</code>, <code>--nodes</code>, <code>--warehouses</code>, and <code>--historgrams</code> arguments, run the benchmark:</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash"> ./tpccbenchmark  --config=${MY_TPCC_WORKLOAD_FILE} \
   --execute=true  \
   --nodes=${YB_NODE_1} \
   --warehouses=1 \
   --histograms</code></pre></div>

	<ul>
		<li>Verify the benchmark is running.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">13:51:09,918 (DBWorkload.java:204) INFO  - Configuration -&gt; nodes: [123.123.123.1], port: 5433, startWH: 1, warehouses: 10, total warehouses across shards: 10, terminals: 100, dbConnections: 10, loaderThreads: 10
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-2 - Starting...
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-2 - Start completed.
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-3 - Starting...
[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-3 - Start completed.
13:51:35,705 (DBWorkload.java:234) INFO  - ======================================================================

{
    Benchmark = TPCC {BenchmarkModule}
    Configuration = config/workload_all.xml
    Driver = org.postgresql.Driver
    URL = [123.123.123.1]
    Isolation = TRANSACTION_REPEATABLE_READ
    Scale Factor = 10
}

13:51:35,705 (DBWorkload.java:235) INFO  - ======================================================================
13:51:35,722 (DBWorkload.java:468) INFO  - Creating 100 virtual terminals...
13:51:35,796 (DBWorkload.java:474) INFO  - Launching the TPCC Benchmark with 1 Phase...
13:51:35,809 (ThreadBench.java:310) INFO  - PHASE START :: [Workload=TPCC] [Serial=false] [Time=1800] [WarmupTime=0] [Rate=10000] [Arrival=REGULAR] [Ratios=[45.0, 43.0, 4.0, 4.0, 4.0]] [ActiveWorkers=100]
13:51:35,810 (ThreadBench.java:456) INFO  - MEASURE :: Warmup complete, starting measurements.
14:21:35,772 (ThreadBench.java:414) INFO  - TERMINATE :: Waiting for all terminals to finish ..
14:22:20,981 (ThreadBench.java:473) INFO  - Attempting to stop worker threads and collect measurements
14:22:20,987 (ThreadBench.java:224) INFO  - Starting WatchDogThread
14:22:21,011 (DBWorkload.java:511) INFO  - ======================================================================
</code></pre></div>

	<h2 id="review-the-benchmark-results">Review the benchmark results</h2>

	<p>When the benchmark completes, you will be able to review the results in the terminal.</p>

	<ul>
		<li>When the benchmark completes, review the Results, including the <strong>TPM-C</strong> number, <strong>Efficiency</strong>, and <strong>Throughput</strong>. Also review the Latency and Work Task Latencies results.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">14:22:21,014 (DBWorkload.java:522) INFO  -
================RESULTS================
             TPM-C |             126.73
        Efficiency |             98.55%
Throughput (req/s) |               4.75

14:22:21,036 (DBWorkload.java:689) INFO  -
======================LATENCIES (INCLUDE RETRY ATTEMPTS)=====================
 Transaction |  Count   | Avg. Latency | P99 Latency | Connection Acq Latency
    NewOrder |     3802 |        19.19 |       48.66 |                   2.89
     Payment |     3742 |        11.98 |       29.36 |                   0.95
 OrderStatus |      326 |         6.29 |       25.85 |                   1.57
    Delivery |      343 |        63.33 |      184.60 |                   1.78
  StockLevel |      338 |        20.83 |       85.70 |                   0.24
        All  |     8551 |        17.38 |       95.43 |                   1.84

14:22:21,074 (DBWorkload.java:633) INFO  -
=======================WORKER TASK LATENCIES=======================
 Transaction |     Task     |  Count   | Avg. Latency | P99 Latency
    NewOrder |   Fetch Work |     3802 |         0.07 |        3.79
    NewOrder |       Keying |     3802 |     18003.74 |    18005.02
    NewOrder |Op With Retry |     3802 |        22.31 |      228.44
    NewOrder |     Thinking |     3802 |     11945.93 |    57887.91
     Payment |   Fetch Work |     3776 |         0.06 |        1.27
     Payment |       Keying |     3776 |      3003.73 |     3005.03
     Payment |Op With Retry |     3776 |        14.06 |       85.91
     Payment |     Thinking |     3776 |     11837.72 |    55752.92
 OrderStatus |   Fetch Work |      326 |         0.06 |        0.04
 OrderStatus |       Keying |      326 |      2003.78 |     2005.04
 OrderStatus |Op With Retry |      326 |         7.91 |       26.15
 OrderStatus |     Thinking |      326 |      9702.81 |    52510.19
    Delivery |   Fetch Work |      343 |         0.07 |        2.45
    Delivery |       Keying |      343 |      2003.80 |     2005.08
    Delivery |Op With Retry |      343 |        65.14 |      278.49
    Delivery |     Thinking |      343 |      4411.94 |    19129.31
  StockLevel |   Fetch Work |      338 |         0.02 |        0.03
  StockLevel |       Keying |      338 |      2003.65 |     2005.02
  StockLevel |Op With Retry |      338 |        21.09 |       85.76
  StockLevel |     Thinking |      338 |      5186.73 |    24646.16
        All  |   Fetch Work |     8585 |         0.06 |        2.45
        All  |       Keying |     8585 |      9529.42 |    18004.98
        All  |Op with Retry |     8585 |        19.80 |      145.40
        All  |     Thinking |     8585 |     11246.03 |    55505.03
        All  |          All |     8585 |     20795.31 |    68765.58
      </code></pre></div>

	<p>In addition to the terminal output, there are two files that your can also review: <code>output.json</code> and <code>results/oltpbench.csv</code>. The <code>output.json</code> file contains the results of the benchmark is JSON format.</p>

	<ul>
		<li>Review the <code>output.json</code> file.</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">cat results/json/output.json</code></pre></div>

	<p>The <code>results/oltpbench.csv</code> file contains the transaction details such as:</p>

	<ul>
		<li>

			<p>Transaction Name</p>
		</li>
		<li>

			<p>Start Time (nanoseconds)</p>
		</li>
		<li>

			<p>Connection Latency (microseconds)</p>
		</li>
		<li>

			<p>OperationLatency (microseconds)</p>
		</li>
		<li>

			<p>Review the <code>oltpbench.csv</code> file.</p>
		</li>
	</ul>
	<div class="highlight"><pre><code class="language-bash">cat results/oltpbench.csv</code></pre></div>

	<h2 id="experiment-on-your-own">Experiment on your own</h2>

	<p>Now that you have a baseline benchmark, it is time to experiment. Here a some ideas:</p>

	<ul>
		<li>Modify your <code>config/my_workload_all.xml</code>, for example, changing <code>&lt;useKeyingTime&gt;</code> and <code>&lt;useThinkTime&gt;</code> to <code>false</code>.</li>
		<li>Create a Yugabyte cluster with TLS/SSL enabled for node to node communications and run the previous benchmark using a SSL cert.</li>
		<li>Double the number of warehouses and run the same benchmark.</li>
		<li>Double the nodes in the cluster and run the previous benchmark.</li>
		<li>Spin up a multi-region cluster, implement tablespaces, and run the same benchmark.</li>
	</ul>

	<p>
		<br>
	</p>

	<h2 id="clean-up">
		<br>
	</h2>

	<h2 id="reflection">Reflection</h2>

	<p>You installed the Yugabyte TPCC benchmark, loaded data in your cluster, ran you own custom workload, and reviewed the results of your benchmark. Ideally, you also experimented with running various workloads and cluster topologies. As &nbsp;learning outcome, you now have a better understanding of how to run a benchmark, analyze benchmarks results, and customize a benchmark as well as a Yugabyte cluster topology.</p>

	<p>
		<br>
	</p>

	<p>
		<br>
	</p>
	<hr>

	<h3>Nicely done!</h3>To continue, in the footer bar of this Course Player, please select <span style="color: rgb(255, 255, 255); background-color: rgb(71, 85, 119);"><strong>&nbsp;NEXT &rarr;&nbsp;</strong></span>.

	<p>
		<br>
	</p>
</div>
